---
title: "Introduction to theft"
author: "Trent Henderson"
date: "`r Sys.Date()`"
output: 
  rmarkdown::html_vignette:
    toc: true
    toc_depth: 4
vignette: >
  %\VignetteIndexEntry{Introduction to theft}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---
  
```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  fig.height = 7,
  fig.width = 7,
  warning = FALSE,
  fig.align = "center"
)
```

```{r setup, message = FALSE, warning = FALSE}
library(dplyr)
library(ggplot2)
library(e1071)
library(theft)
```

## Purpose

`theft` facilitates user-friendly access to a structured analytical workflow for the extraction, analysis, and visualisation of time-series features. As of `v0.5.4`, `theft` now acts as a 'mothership' one-stop-shop package ecosystem which calls several other smaller, more bespoke packages:

<img src="theft-ecosystem.png" alt="The theft R package ecosystem" />

Users are encouraged to either use `theft` to access all the functionality, or, if they require only specific functions, to explore the individual packages. That being said, `theft` provides a structured workflow for taking users from data import through to detailed insights about their temporal data. This structured workflow is presented in the graphic below (note that `theft` has many more functions than displayed in this graphic---keep reading for more):

<img src="workflow-graphic_v05.png" width="700" alt="Structured workflow of the theft package for R" />

## Core calculation functions

To explore package functionality, we are going to use a dataset that comes standard with `theft` called `simData`. This dataset contains a collection of randomly generated time series for six different types of processes. The dataset can be accessed via:
  
```{r, message = FALSE, warning = FALSE, eval = FALSE}
theft::simData
```

The data follows the following structure:
  
```{r, message = FALSE, warning = FALSE}
head(simData)
```

### Calculating feature summary statistics

The core function that automates the calculation of the feature statistics at once is `calculate_features`. As of `v0.5.4`, `calculate_features` is a wrapper for the [`purloiner`](https://github.com/hendersontrent/purloiner) function `extract_features`, such that `purloiner` now acts as both a stanalone package and the feature extraction module of `theft`. You can choose which subset of features to calculate with the `feature_set` argument. The choices are currently `"catch22"`, `"feasts"`, `"basicproperties"`, `"Kats"`, `"tsfeatures"`, `"tsfresh"`, and/or `"TSFEL"`.

Note that `Kats`, `tsfresh` and `TSFEL` are Python packages. The R package `reticulate` is used to call Python code that uses these packages and applies it within the broader *tidy* data philosophy embodied by `theft`. At present, depending on the input time-series, `theft` provides access to $>1200$ features. 

#### Installing Python feature sets

Prior to using `theft` (only if you want to use the `Kats`, `tsfresh` or `TSFEL` feature sets; the R-based sets will run fine) you should have a working Python 3.9 installation and run the function `install_python_pkgs(python_path, path)` after first installing `theft`, where the `python_path` argument is the filepath to the location of Python 3.9 on your machine and the `path` argument is the location you wish to install the Python libraries and virtual environment to on your machine. Note that as of `v0.5.4`, `install_python_pkgs` is a wrapper for `purloiner::install_python_libs`.

For example, if you wanted to install the Python libraries and the resulting virtual environment in `"C:/Users/User/Desktop/theft"` and Python 3.9 is located at `"/usr/bin/python"` on your machine, you would run the following after first having installed `theft`:

```{r, eval = FALSE}
install_python_pkgs("C:/Users/User/Desktop/theft", "/usr/bin/python")
```

If you want to use any of the Python-based packages, you must first tell R which Python and/or virtual environment on your computer contains the installed libraries. This can be done in `theft` via the `init_theft` function, which has two arguments:

1. `python_path` -- the filepath to the version of Python you wish to use (i.e., the same as was entered into `install_python_pkgs` if you ran that first)
2. `venv_path` -- the filepath to the Python virtual environment where `tsfresh`, `TSFEL`, and/or `Kats` are installed (i.e., the path returned in the console message from `install_python_pkgs` if you ran that function first)

However, you do not necessarily have to use this convenience function. If you have another method for pointing R to the correct Python (such as `reticulate` or `findpython`), you can use those in your workflow instead.

 Note that as of `v0.5.4`, `init_theft` is a wrapper for `purloiner::init_purloin`.

**NOTE: You only need to call ** `init_theft` **or your other solution once per session.**

#### Calculating features

You are then ready to use the rest of the package's functionality, beginning with the extraction of time-series features. `calculate_features` (and `purloiner::extract_features`) take the following arguments: 

* `data`---data.frame with at least 3 columns: id variable, time variable, value variable
* `id_var`--- character specifying the ID variable to identify each time series. Defaults to `"id"`
* `time_var`---character specifying the time index variable. Defaults to `"timepoint"`
* `values_var`---character specifying the values variable. Defaults to `"values"`
* `group_var`---character specifying the grouping variable that each unique series sits under (if one exists). Defaults to `NULL`
* `feature_set`---character or vector of characters denoting the set of time-series features to calculate. Defaults to `"catch22"`
* `catch24`---Boolean specifying whether to compute `catch24` in addition to `catch22` if `catch22` is one of the feature sets selected. Defaults to `FALSE`
* `tsfresh_cleanup`---Boolean specifying whether to use the in-built `tsfresh` relevant feature filter or not. Defaults to `FALSE`
* `seed`---integer denoting a fixed number for R's random number generator to ensure reproducibility. Defaults to `123`

Here is an example call with the `catch22` and `basicproperties` sets:
  
```{r, message = FALSE, warning = FALSE}
feature_matrix <- calculate_features(data = simData, 
                                     id_var = "id", 
                                     time_var = "timepoint", 
                                     values_var = "values", 
                                     group_var = "process", 
                                     feature_set = c("catch22", "basicproperties"),
                                     seed = 123)
```

Note that for the `catch22` set you can set the additional `catch24` argument to calculate the mean and standard deviation in addition to the standard 22 features:
  
```{r, message = FALSE, warning = FALSE, eval = FALSE}
feature_matrix <- calculate_features(data = simData, 
                                     id_var = "id", 
                                     time_var = "timepoint", 
                                     values_var = "values", 
                                     group_var = "process", 
                                     feature_set = "catch22",
                                     catch24 = TRUE,
                                     seed = 123)
```

NOTE: If using the `tsfresh` feature set, you might want to consider the `tsfresh_cleanup` argument to `calculate_features`. This argument defaults to `FALSE` and specifies whether to use the in-built `tsfresh` relevant feature filter or not.

### Comparison of feature sets

For a detailed comparison of the six feature sets, see [this paper](https://ieeexplore.ieee.org/document/9679937) for a detailed review^[T. Henderson and B. D. Fulcher, "An Empirical Evaluation of Time-Series Feature Sets," 2021 International Conference on Data Mining Workshops (ICDMW), 2021, pp. 1032-1038, doi: 10.1109/ICDMW53433.2021.00134.].

## Data quality checks

The `calculate_features` function returns an object of class `feature_calculations`. Objects of this type are purposefully looked-for by other functions in `theft`. Because it is a class, simple methods such as `plot()` can be called on the object to produce a range of statistical graphics. The first is a visualisation of the data types of the calculated feature vectors. This is useful for inspecting which features might need to be dropped due to large proportions of undesirable (e.g., `NA`, `NaN` etc.) values. We can specify the plot `type = "quality` to make this graphic:

```{r, message = FALSE, warning = FALSE}
plot(feature_matrix, type = "quality")
```

## Normalising/scaling functions

Putting calculated feature vectors on an equal scale is crucial for any statistical or machine learning model as variables with high variance can adversely impact the model's capacity to fit the data appropriately, learn appropriate weight values, or minimise a loss function. `theft` includes function `normalise` to rescale either the whole `feature_calculations` object, or a single vector of values (e.g. values for all participants on just the `SB_BinaryStats_mean_longstretch1` feature). Four normalisation methods are offered:

* z-score---`"zScore"`
* Sigmoid---`"Sigmoid"`
* Outlier-robust Sigmoid (credit to Ben Fulcher for creating the original [MATLAB version](https://github.com/benfulcher/hctsa)) -- `"RobustSigmoid"`
* Min-max---`"MinMax"`
* Maximum absolute---`"MaxAbs"`

Normalisation on the whole `feature_calculations` object can be performed in one line:

```{r, message = FALSE, warning = FALSE}
normed <- normalise(feature_matrix, norm_method = "zScore", unit_int = FALSE)
```

For single vector normalisation, all you need to do is pass in a vector as `normalise` checks for object classes. If you wish to rescale values into the unit interval $[0,1]$ after applying the selected normalisation method, you can set `unit_int = TRUE`.

Note that as of `v0.5.4`, `normalise` is a wrapper for the [`normaliseR`](https://github.com/hendersontrent/normaliseR) function `normaliseR::normalise` such that `normaliseR` now acts as both a stanalone package and the rescaling module of `theft`. An alternate spelling version `normalize` also exists.

## Data visualisation and low-dimensional projections

The package also comes with additional statistical and graphical functionality:

* Feature by time-series matrix as a heatmap
* Low dimensional projections of the feature space and plotting as a scatterplot
* Pairwise feature correlation matrix as a heatmap

### Feature matrices

The function calling `type = "matrix"` in `plot()` on a `feature_calculations` object takes itand produces a `ggplot` object heatmap showing the feature vectors across the `x` axis and each time series down the `y` axis. Prior to plotting, the function hierarchically clusters the data across both rows and columns to visually highlight the empirical structure. Note that you have several options for the hierarchical clustering linkage algorithm to use:

* `"average"` (default)
* `"ward.D"`
* `"ward.D2"`
* `"single"`
* `"complete"`
* `"mcquitty"`
* `"median"`
* `"centroid"`

See the [`hclust` documentation](https://www.rdocumentation.org/packages/stats/versions/3.6.2/topics/hclust) for more information.

Note that the legend for this plot (and other matrix visualisations in `theft`) have been discretised for visual clarity as continuous legends can be difficult to interpret meaningful value differences easily.

```{r, message = FALSE, warning = FALSE}
plot(feature_matrix, type = "matrix", norm_method = "RobustSigmoid")
```

You can control the normalisation type with the `norm_method` argument, whether to rescale to the unit interval after normalisation with the `unit_int` argument, and the hierarchical clustering method with the `clust_method` argument (the example above used defaults so manual specification was not needed).

### Individual feature distributions

Plotting the entire feature matrix is useful, but sometimes we wish to understand the distributions of individual features. This is particularly useful if there are different groups in your data (such as in a time-series classification context). We can again use the `plot()` generic here to draw violin plots through setting `type = "violin"`. Note that for violin plots, we also need to tell the function which features we wish to plot (i.e., a vector of characters specifying feature names from the `names` column in your `feature_calculations` object). For simplicity, we will just plot two random features from `catch22` here:

```{r, message = FALSE, warning = FALSE}
plot(feature_matrix, type = "violin", 
     feature_names = c("CO_f1ecac", "PD_PeriodicityWang_th0_01"))
```

Note that when using these defined `plot()` generics, you can pass any additional arguments to certain geoms to control the plot look through the `...` argument in the `plot()` function. Below is a guide to where these arguments go depending on the plot type:

* `type = "quality"`---`...` goes to `ggplot2::geom_bar`
* `type = "matrix"`---`...` goes to `ggplot2::geom_raster`
* `type = "cor"`---`...` goes to `ggplot2::geom_raster`
* `type = "violin"`---`...` goes to `ggplot2::geom_point`

For example, we may wish to control the point size and transparency in the above plot (not rendered here for space):

```{r, eval = FALSE}
plot(feature_matrix, type = "violin", 
     feature_names = c("CO_f1ecac", "PD_PeriodicityWang_th0_01"), 
     size = 0.7, alpha = 0.9)
```

### Low dimensional projections

The function `reduce_dims` takes the `feature_calculations` object and reduces the dimensionality down to two dimensions appropriate for a scatterplot using one of the following methods:

* Principal components analysis (PCA)---`"PCA"`
* $t$-Stochastic Neighbor Embedding ($t$-SNE)---`"tSNE"`
* Classical multidimensional scaling (MDS)---`"ClassicalMDS"`
* Kruskal’s non-metric multidimensional scaling---`"KruskalMDS"`
* Sammon’s non-linear mapping non-metric multidimensional scaling---`"SammonMDS"`
* Uniform Manifold Approximation and Projection for Dimension Reduction (UMAP)---`"UMAP"`

As of `v0.5.4`, `reduce_dims` is a wrapper for the [`pilfer`](https://github.com/hendersontrent/pilfer) function `pilfer::reduce_dimensions` such that `pilfer` now acts as both a stanalone package and the dimension reduction module of `theft`. The result of `reduce_dims` is stored in a custom object class called `low_dimension`. The function takes the following arguments:

* `data`---`feature_calculations` object containing the raw feature matrix produced by `purloiner::extract_features`
* `norm_method`---character denoting the rescaling/normalising method to apply. Can be one of `"zScore"`, `"Sigmoid"`, `"RobustSigmoid"`, `"MinMax"`, or `"MaxAbs"`. Defaults to `"zScore"`
* `unit_int`---Boolean whether to rescale into unit interval $[0,1]$ after applying normalisation method. Defaults to `FALSE`
* `low_dim_method`---character specifying the low dimensional embedding method to use. Defaults to `"PCA"`
* `seed`---integer to fix R's random number generator to ensure reproducibility. Defaults to `123`
* `...` arguments to be passed to `stats::prcomp` or `Rtsne::Rtsne`, `stats::cmdscale`, `MASS::isoMDS`, `MASS::sammon`, or `umap::umap` depending on selection in `low_dim_method`

Here is an example call:

```{r, message = FALSE, warning = FALSE}
low_dim <- reduce_dims(feature_matrix, 
                       norm_method = "RobustSigmoid", 
                       unit_int = TRUE,
                       low_dim_method = "PCA", 
                       seed = 123)
```

We can similarly call `plot()` on this object to produce a two-dimensional scatterplot of the results:

```{r, message = FALSE, warning = FALSE}
plot(low_dim)
```

Similarly, we could use $t$-SNE instead and make use of the `...` additional arguments to control hyperparameters such as `perplexity`. Shaded covariance ellipses can also be disabled when plotting `low_dimension` objects by setting `show_covariance = FALSE`:

```{r, message = FALSE, warning = FALSE}
low_dim2 <- reduce_dims(feature_matrix, 
                        norm_method = "RobustSigmoid", 
                        unit_int = TRUE,
                        low_dim_method = "tSNE", 
                        perplexity = 10,
                        seed = 123)

plot(low_dim2, show_covariance = FALSE)
```

You can consult help files to get a list of potential arguments by calling `?` on the appropriate dimension reduction function, such as `?prcomp` or `?Rtsne`.

### Pairwise correlations

You can plot correlations between feature vectors using `plot(type = "cor")` on a `feature_calculations` object:

```{r, message = FALSE, warning = FALSE}
plot(feature_matrix, type = "cor")
```

Similarly, you can control the normalisation type with the `norm_method` argument and the hierarchical clustering method with the `clust_method` argument (the example above used defaults so manual specification was not needed).

## Time-series classification

### Feature-by-feature

Since feature-based time-series analysis has shown particular promise for classification problems, `theft` includes functionality for exploring group separation. The function `tsfeature_classifier` enables you to fit a range of classification models to enable statistical comparisons using the resampling methodology presented in [this paper](https://pakdd2023.org/wp-content/uploads/2023/05/pakdd23_w1_p3.pdf) for a detailed review^[T. Henderson, A. G., Bryant, and B. D. Fulcher, "Never a Dull Moment: Distributional Properties as a Baseline for Time-Series Classification", 27th Pacific-Asia Conference on Knowledge Discovery and Data Mining, 2023.]. This function is meant to serve as a fast answer that can be used to guide analysis and not a replacement for the development of a careful statistical pipeline. `tsfeature_classifier` has the following arguments:

* `data`---`feature_calculations` object containing the raw feature matrix produced by `calculate_features` with an included `group` column as per `theft::calculate_features`
* `classifier`---`function` specifying the classifier to fit. Should be a function with 2 arguments: `formula` and `data`. Please note that `tsfeature_classifier` $z$-scores data prior to modelling using the train set's information so disabling default scaling if your function uses it is recommended. Defaults to `NULL` which means the following linear SVM is fit: `classifier = function(formula, data){mod <- e1071::svm(formula, data = data, kernel = "linear", scale = FALSE, probability = TRUE)}`
* `train_size`---Numeric value denoting the proportion of samples to use in the training set. Defaults to `0.75`
* `n_resamples`---Integer denoting the number of resamples to calculate. Defaults to `30`
* `by_set`---Boolean specifying whether to compute classifiers for each feature set. Defaults to `TRUE` (see below section "Multi-feature" for more on this). If `FALSE`, the function will instead find the best individually-performing features
* `use_null`---Boolean whether to fit null models where class labels are shuffled in order to generate a null distribution that can be compared to performance on correct class labels. Defaults to `FALSE`. This is known as permutation testing
* `seed`---Integer to fix R's random number generator to ensure reproducibility. Defaults to `123`
* `preference`--- Character denoting which feature set to keep (meaning the others will be filtered out) between `"feasts"`, `"tsfeatures"`, and `"Kats"` since there is considerable overlap between these three sets. Defaults to `"feasts"`. Duplicates will **not** be removed from the respective non-preferenced sets when computing set-level results to ensure fairness. They are only filtered out for either the construction of the set of "All features" if `by_set = TRUE` and when computing individual feature results (to reduce redundant calculations)

*NOTE:* You can apply duplicate filtering to any `feature_calculations` object through the function `filter_duplicates`. This function only has 2 arguments: `data` (the  `feature_calculations` object) and `preference` (same as above). For example, if you assumed that we calculated features from all the sets, you could run the following upfront:

```{r, eval = FALSE}
feature_matrix_filt <- filter_duplicates(feature_matrix, preference = "feasts")
```

Since we are interested in individual features in this section, we will calculate both main and null results for each feature using just `5` resamples for efficiency (in practice, we would use more!) with the default linear SVM:

```{r, message = FALSE, warning = FALSE}
feature_classifiers <- tsfeature_classifier(feature_matrix, 
                                            by_set = FALSE, 
                                            n_resamples = 5, 
                                            use_null = TRUE)
```

To show you how simple it is to specify a different classifier, we can instead maybe use a radial basis function SVM (though you are absolutely not limited to just `e1071` models! You can use anything that can be used with R's `predict` generic as `tsfeature_classifier` internally constructs confusion matrices from model predictions):

```{r, message = FALSE, warning = FALSE}
myclassifier <- function(formula, data){
  mod <- e1071::svm(formula, data = data, kernel = "radial", scale = FALSE, 
                    probability = TRUE)
}

feature_classifiers_radial <- tsfeature_classifier(feature_matrix, 
                                                   classifier = myclassifier, 
                                                   by_set = FALSE, 
                                                   n_resamples = 5, 
                                                   use_null = TRUE)
```

While have raw classification results is useful, we often also would like to statistical evaluate some facet of it. `theft` includes the function `compare_features` for doing this. `compare_features` calls the [`correctR`](https://github.com/hendersontrent/correctR/) package under-the-hood for access to corrected test statistics for resampled data. In the case of random subsampling (such as the resample procedure implemented by `tsfeature_classifier`), the standard $t$-test inflates Type I error due to an underestimation of the variance, as found by Dietterich (1998)^[Dietterich, T. G. (1998). Approximate Statistical Tests for Comparing Supervised Classification Learning Algorithms. Neural Computation, 10(7)]. Nadeau and Bengio (2003) proposed a solution which `correctR` implements as:

$$
t = \frac{\frac{1}{n} \sum_{j=1}^{n}x_{j}}{\sqrt{(\frac{1}{n} + \frac{n_{2}}{n_{1}})\sigma^{2}}}
$$

where $n$ is the number of resamples (NOTE: $n$ is *not* sample size), $n_{1}$ is the number of samples in the training data, and $n_{2}$ is the number of samples in the test data. $\sigma^{2}$ is the variance estimate used in the standard paired $t$-test (which simply has $\frac{\sigma}{\sqrt{n}}$ in the denominator where $n$ is the sample size in this case).

`compare_features` takes the following arguments:

* `data`---List object containing the classification outputs produce by `tsfeature_classifier`
* `metric`---Character denoting the classification performance metric to use in statistical testing. Can be one of `"accuracy"`, `"precision"`, `"recall"`, `"f1"`. Defaults to `"accuracy"`
* `by_set`---Boolean specifying whether you want to compare feature sets (if `TRUE`) or individual features (if `FALSE`). Defaults to `TRUE` but this is contingent on whether you computed by set or not in `tsfeature_classifier`
* `hypothesis`---Character denoting whether p-values should be calculated for each feature set or feature (depending on `by_set` argument) individually relative to the null if `use_null = TRUE` in `tsfeature_classifier` through `"null"`, or whether pairwise comparisons between each set or feature should be conducted on main model fits only through `"pairwise"`. Defaults to `"null"`
* `p_adj`---Character denoting the adjustment made to p-values for multiple comparisons. Should be a valid argument to [`stats::p.adjust`](https://www.rdocumentation.org/packages/stats/versions/3.6.2/topics/p.adjust). Defaults to `"none"` for no adjustment. `"holm"` is recommended as a starting point if adjustments are sought

We can use `compare_features` to evaluate how well each individual feature performs relative to its empirical null distribution (noting that we are using the defaults for the other arguments for code cleanliness):

```{r, message = FALSE, warning = FALSE}
feature_vs_null <- compare_features(feature_classifiers, 
                                    by_set = FALSE, 
                                    hypothesis = "null")

head(feature_vs_null)
```

Or to conduct pairwise comparisons between individual features:

```{r, message = FALSE, warning = FALSE}
pairwise_features <- compare_features(feature_classifiers, 
                                      by_set = FALSE, 
                                      hypothesis = "pairwise", 
                                      p_adj = "holm")

head(pairwise_features)
```

We can then use `ggplot2` to summarise and visualise our results. Here is a pairwise correlation plot between the top 10 features in `catch22` for this toy problem. We are just simply filtering the original full feature data and making use of the `plot` generic defined for objects of class `feature_calculations`:

```{r, message = FALSE, warning = FALSE}
top_10 <- feature_vs_null %>% 
  dplyr::slice_min(p.value, n = 10) %>% 
  dplyr::select(c(feature_set, original_names, p.value))

feature_matrix_filt <- feature_matrix[[1]] %>% 
  dplyr::filter(feature_set %in% top_10$feature_set & names %in% top_10$original_names)

feature_matrix_filt <- structure(list(feature_matrix_filt), 
                                 class = "feature_calculations")

plot(feature_matrix_filt, type = "cor")
```

We can also easily draw a violin plot of the top 10 features to visualise the distributions by group:

```{r, message = FALSE, warning = FALSE}
plot(feature_matrix_filt, 
     type = "violin", 
     feature_names = top_10$original_names)
```

Finally, `theft` also contains a function `calculate_interval` for summarising the results of `tsfeature_classifier`. `calculate_interval` takes the following arguments:

* `data`---list object containing the classification outputs produce by `tsfeature_classifier`
* `metric`---character denoting the classification performance metric to calculate intervals for. Can be one of `"accuracy"`, `"precision"`, `"recall"`, `"f1"`. Defaults to `"accuracy"`
* `by_set`---Boolean specifying whether to compute intervals for each feature set. Defaults to `TRUE`. If `FALSE`, the function will instead calculate intervals for each feature
* `type`---character denoting whether to calculate a $\pm$ SD interval with `"sd"`, confidence interval based off the $t$-distribution with    `"qt"`, or based on a quantile with `"quantile"`. Defaults to `"sd"`
* `interval`---numeric scalar denoting the width of the interval to calculate. Defaults to `1` if `type = "sd"` to produce a $\pm 1$ SD interval. Defaults to `0.95` if `type = "qt"` or `type = "quantile"` for a $95\%$ interval
* `model_type`---character denoting whether to calculate intervals for main models with `"main"` or null models with `"null"` if the `use_null` argument when using `tsfeature_classifier` was `use_null = TRUE`. Defaults to `"main"`

We can evidently use `calculate_interval` to produce a variety of different summaries for us. For example, we might wish to compute the $\pm1$ SD interval for each feature's main model classification accuracy values (note that the defaults for the function do this for us, so we only need to set `by_set = FALSE` manually):

```{r, message = FALSE, warning = FALSE}
calculate_interval(feature_classifiers, by_set = FALSE)
```

### Multi-feature

Since `theft` contains entire sets of features, we can also use `tsfeature_classifier` to compare them at the set level through the `by_set` argument:

```{r, message = FALSE, warning = FALSE}
set_classifiers <- tsfeature_classifier(feature_matrix, 
                                        by_set = TRUE, 
                                        n_resamples = 5, 
                                        use_null = TRUE)

head(set_classifiers)
```

Since we calculated `catch22` and `basicproperties` in this vignette, the only other comparate set is `"All features"` which is automatically always included by default. Similar to the individual feature case, we can also use `calculate_interval` combined with `ggplot2` to summarise our findings. Here is a comparison of mean accuracy $\pm 1SD$ between feature sets:
  
```{r, message = FALSE, warning = FALSE}
interval_calcs <- calculate_interval(set_classifiers)

interval_calcs %>%
  ggplot2::ggplot(ggplot2::aes(x = reorder(feature_set, -.mean), y = .mean, 
                               colour = feature_set)) +
  ggplot2::geom_errorbar(ggplot2::aes(ymin = .lower, ymax = .upper)) +
  ggplot2::geom_point(size = 5) +
  ggplot2::labs(x = "Feature set",
                y = "Classification accuracy") +
  ggplot2::scale_colour_brewer(palette = "Dark2") +
  ggplot2::theme_bw() +
  ggplot2::theme(legend.position = "none",
                 panel.grid.minor = ggplot2::element_blank())
```

As you can see, `calculate_interval` provides a fast summary of average performance at the set level---and with a useful reference point of the potentially huge set of all calculated features.

## Reading and processing hctsa-formatted files

As `theft` is based on the foundations laid by [`hctsa`](https://github.com/benfulcher/hctsa), there is also functionality for reading in `hctsa`-formatted Matlab files and automatically processing them into tidy dataframes ready for feature extraction in `theft`. The `process_hctsa_file` function takes a string filepath to the Matlab file and does all the work for you, returning a dataframe with naming conventions consistent with other `theft` functionality. As per `hctsa` specifications for [Input File Format 1](https://hctsa-users.gitbook.io/hctsa-manual/calculating/input_files), this file should have 3 variables with the following exact names: `timeSeriesData`, `labels`, and `keywords`. The filepath can be a local drive path or a URL.
